{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80ec19c4-b270-4229-bb88-a9f6fcf740c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'NEGATIVE': 0, 'NEUTRAL': 1, 'POSITIVE': 2}\n",
      "Selected 20 features: Index(['mean_4_a', 'max_q_1_a', 'max_q_3_a', 'min_0_a', 'min_q_7_a',\n",
      "       'logm_8_a', 'logm_9_a', 'logm_42_a', 'logm_64_a', 'entropy0_a',\n",
      "       'fft_136_a', 'fft_139_a', 'mean_4_b', 'max_q_3_b', 'max_q_13_b',\n",
      "       'logm_8_b', 'logm_9_b', 'logm_42_b', 'logm_64_b', 'entropy0_b'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import time\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('emotions.csv')\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = data.drop(columns=['label'])  # Features\n",
    "y = data['label']  # Labels\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the target labels (NEGATIVE -> 0, NEUTRAL -> 1, POSITIVE -> 2)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Check encoding mapping\n",
    "print(\"Label Encoding Mapping:\", dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))\n",
    "\n",
    "# Apply LASSO for feature selection\n",
    "alpha = 0.09  # Regularization strength (adjust as needed)\n",
    "lasso = Lasso(alpha=alpha)\n",
    "lasso.fit(X_scaled, y)\n",
    "\n",
    "# Identify selected features (non-zero coefficients)\n",
    "selected_features_indices = np.where(lasso.coef_ != 0)[0]\n",
    "selected_features = X.columns[selected_features_indices]\n",
    "print(f\"Selected {len(selected_features)} features: {selected_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a01d56d-e499-47fa-916a-c4ac8d3cd924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the dataset with selected features\n",
    "X = X_scaled[:, selected_features_indices]\n",
    "\n",
    "# Split the feature-selected data into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "271b51ab-772f-465b-94e2-d09986e517ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8923\n",
      "Logistic Regression Precision: 0.8948\n",
      "Logistic Regression Recall: 0.8908\n",
      "Logistic Regression F1 Score: 0.8907\n",
      "Training time for Logistic Regression: 0.0861 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "logreg_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "logreg_accuracy = accuracy_score(y_test, y_pred_logreg)\n",
    "\n",
    "# Generate classification report\n",
    "report_logreg = classification_report(y_test, y_pred_logreg, output_dict=True)\n",
    "\n",
    "# Extract precision, recall, f1-score for each class and overall\n",
    "precision_logreg = report_logreg['macro avg']['precision']\n",
    "recall_logreg = report_logreg['macro avg']['recall']\n",
    "f1_logreg = report_logreg['macro avg']['f1-score']\n",
    "\n",
    "# Print metrics for Logistic Regression\n",
    "print(f\"Logistic Regression Accuracy: {logreg_accuracy:.4f}\")\n",
    "print(f\"Logistic Regression Precision: {precision_logreg:.4f}\")\n",
    "print(f\"Logistic Regression Recall: {recall_logreg:.4f}\")\n",
    "print(f\"Logistic Regression F1 Score: {f1_logreg:.4f}\")\n",
    "print(f\"Training time for Logistic Regression: {training_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfab42a6-92bd-4540-90f0-14a9102f18c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9391\n",
      "SVM Precision: 0.9400\n",
      "SVM Recall: 0.9375\n",
      "SVM F1 Score: 0.9378\n",
      "Training time for SVM: 0.1166 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the SVM model with a radial basis function (RBF) kernel\n",
    "svm_model = SVC(kernel='rbf', gamma='scale')\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "# Generate classification report\n",
    "report_svm = classification_report(y_test, y_pred_svm, output_dict=True)\n",
    "\n",
    "# Extract precision, recall, f1-score for each class and overall\n",
    "precision_svm = report_svm['macro avg']['precision']\n",
    "recall_svm = report_svm['macro avg']['recall']\n",
    "f1_svm = report_svm['macro avg']['f1-score']\n",
    "\n",
    "# Print metrics for SVM\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(f\"SVM Precision: {precision_svm:.4f}\")\n",
    "print(f\"SVM Recall: {recall_svm:.4f}\")\n",
    "print(f\"SVM F1 Score: {f1_svm:.4f}\")\n",
    "print(f\"Training time for SVM: {training_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bad2fe0b-d8b7-46fe-af4f-673d7aea60b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB Accuracy: 0.8314\n",
      "GNB Precision: 0.8476\n",
      "GNB Recall: 0.8320\n",
      "GNB F1 Score: 0.8302\n",
      "Training time for GNB: 0.0094 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the GNB model\n",
    "gnb_model = GaussianNB()\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "gnb_model.fit(X_train, y_train)\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_gnb = gnb_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "gnb_accuracy = accuracy_score(y_test, y_pred_gnb)\n",
    "\n",
    "# Generate classification report\n",
    "report_gnb = classification_report(y_test, y_pred_gnb, output_dict=True)\n",
    "\n",
    "# Extract precision, recall, f1-score for each class and overall\n",
    "precision_gnb = report_gnb['macro avg']['precision']\n",
    "recall_gnb = report_gnb['macro avg']['recall']\n",
    "f1_gnb = report_gnb['macro avg']['f1-score']\n",
    "\n",
    "# Print metrics for GNB\n",
    "print(f\"GNB Accuracy: {gnb_accuracy:.4f}\")\n",
    "print(f\"GNB Precision: {precision_gnb:.4f}\")\n",
    "print(f\"GNB Recall: {recall_gnb:.4f}\")\n",
    "print(f\"GNB F1 Score: {f1_gnb:.4f}\")\n",
    "print(f\"Training time for GNB: {training_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b27314f1-e53a-49d7-98b0-5818dc89267f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9274\n",
      "Decision Tree Precision: 0.9264\n",
      "Decision Tree Recall: 0.9264\n",
      "Decision Tree F1 Score: 0.9263\n",
      "Training time for Decision Tree: 0.0364 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "\n",
    "# Generate classification report\n",
    "report_dt = classification_report(y_test, y_pred_dt, output_dict=True)\n",
    "\n",
    "# Extract precision, recall, f1-score for each class and overall\n",
    "precision_dt = report_dt['macro avg']['precision']\n",
    "recall_dt = report_dt['macro avg']['recall']\n",
    "f1_dt = report_dt['macro avg']['f1-score']\n",
    "\n",
    "# Print metrics for Decision Tree\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy:.4f}\")\n",
    "print(f\"Decision Tree Precision: {precision_dt:.4f}\")\n",
    "print(f\"Decision Tree Recall: {recall_dt:.4f}\")\n",
    "print(f\"Decision Tree F1 Score: {f1_dt:.4f}\")\n",
    "print(f\"Training time for Decision Tree: {training_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cffce7e-26df-4ee9-a72e-bf1c3b58f49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.9438\n",
      "KNN Precision: 0.9439\n",
      "KNN Recall: 0.9435\n",
      "KNN F1 Score: 0.9431\n",
      "Training time for KNN: 0.0135 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the KNN model with the number of neighbors (you can tune the n_neighbors parameter)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "# Generate classification report\n",
    "report_knn = classification_report(y_test, y_pred_knn, output_dict=True)\n",
    "\n",
    "# Extract precision, recall, f1-score for each class and overall\n",
    "precision_knn = report_knn['macro avg']['precision']\n",
    "recall_knn = report_knn['macro avg']['recall']\n",
    "f1_knn = report_knn['macro avg']['f1-score']\n",
    "\n",
    "# Print metrics for KNN\n",
    "print(f\"KNN Accuracy: {knn_accuracy:.4f}\")\n",
    "print(f\"KNN Precision: {precision_knn:.4f}\")\n",
    "print(f\"KNN Recall: {recall_knn:.4f}\")\n",
    "print(f\"KNN F1 Score: {f1_knn:.4f}\")\n",
    "print(f\"Training time for KNN: {training_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b5626d5-85ee-4528-95e4-b49e13660c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9742\n",
      "Random Forest Precision: 0.9741\n",
      "Random Forest Recall: 0.9740\n",
      "Random Forest F1 Score: 0.9739\n",
      "Training time for Random Forest: 0.5259 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Random Forest model with a number of trees (n_estimators)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# Generate classification report\n",
    "report_rf = classification_report(y_test, y_pred_rf, output_dict=True)\n",
    "\n",
    "# Extract precision, recall, f1-score for each class and overall\n",
    "precision_rf = report_rf['macro avg']['precision']\n",
    "recall_rf = report_rf['macro avg']['recall']\n",
    "f1_rf = report_rf['macro avg']['f1-score']\n",
    "\n",
    "# Print metrics for Random Forest\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"Random Forest Precision: {precision_rf:.4f}\")\n",
    "print(f\"Random Forest Recall: {recall_rf:.4f}\")\n",
    "print(f\"Random Forest F1 Score: {f1_rf:.4f}\")\n",
    "print(f\"Training time for Random Forest: {training_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69188ea4-4495-46de-b476-26211d3cab74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.6581\n",
      "AdaBoost Precision: 0.5333\n",
      "AdaBoost Recall: 0.6437\n",
      "AdaBoost F1 Score: 0.5459\n",
      "Training time for AdaBoost: 0.3685 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the AdaBoost model directly (no need to specify base_estimator)\n",
    "ada_model = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the AdaBoost model\n",
    "ada_model.fit(X_train, y_train)\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_ada = ada_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "ada_accuracy = accuracy_score(y_test, y_pred_ada)\n",
    "\n",
    "# Generate classification report\n",
    "report_ada = classification_report(y_test, y_pred_ada, output_dict=True)\n",
    "\n",
    "# Extract precision, recall, f1-score for each class and overall\n",
    "precision_ada = report_ada['macro avg']['precision']\n",
    "recall_ada = report_ada['macro avg']['recall']\n",
    "f1_ada = report_ada['macro avg']['f1-score']\n",
    "\n",
    "# Print metrics for AdaBoost\n",
    "print(f\"AdaBoost Accuracy: {ada_accuracy:.4f}\")\n",
    "print(f\"AdaBoost Precision: {precision_ada:.4f}\")\n",
    "print(f\"AdaBoost Recall: {recall_ada:.4f}\")\n",
    "print(f\"AdaBoost F1 Score: {f1_ada:.4f}\")\n",
    "print(f\"Training time for AdaBoost: {training_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5d0fb43-f768-4fad-bf2a-d5c118b63543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4203\n",
      "[LightGBM] [Info] Number of data points in the train set: 1705, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score -1.104495\n",
      "[LightGBM] [Info] Start training from score -1.099199\n",
      "[LightGBM] [Info] Start training from score -1.092181\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM Accuracy: 0.9766\n",
      "LightGBM Precision: 0.9766\n",
      "LightGBM Recall: 0.9760\n",
      "LightGBM F1 Score: 0.9762\n",
      "Training time for LightGBM: 0.1897 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the LightGBM model with the appropriate parameters\n",
    "lgb_model = lgb.LGBMClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the LightGBM model\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "lgb_accuracy = accuracy_score(y_test, y_pred_lgb)\n",
    "\n",
    "# Generate classification report\n",
    "report_lgb = classification_report(y_test, y_pred_lgb, output_dict=True)\n",
    "\n",
    "# Extract precision, recall, f1-score for each class and overall\n",
    "precision_lgb = report_lgb['macro avg']['precision']\n",
    "recall_lgb = report_lgb['macro avg']['recall']\n",
    "f1_lgb = report_lgb['macro avg']['f1-score']\n",
    "\n",
    "# Print metrics for LightGBM\n",
    "print(f\"LightGBM Accuracy: {lgb_accuracy:.4f}\")\n",
    "print(f\"LightGBM Precision: {precision_lgb:.4f}\")\n",
    "print(f\"LightGBM Recall: {recall_lgb:.4f}\")\n",
    "print(f\"LightGBM F1 Score: {f1_lgb:.4f}\")\n",
    "print(f\"Training time for LightGBM: {training_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e4000a9-5973-4101-8b8d-95e33419de40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.9766\n",
      "XGBoost Precision: 0.9767\n",
      "XGBoost Recall: 0.9761\n",
      "XGBoost F1 Score: 0.9762\n",
      "Training time for XGBoost: 0.1914 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the training and test labels\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = XGBClassifier(n_estimators=50, random_state=42, eval_metric='mlogloss')\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Convert predictions back to original labels\n",
    "y_pred_xgb = label_encoder.inverse_transform(y_pred_xgb)\n",
    "\n",
    "# Calculate accuracy\n",
    "xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "\n",
    "# Generate classification report\n",
    "report_xgb = classification_report(y_test, y_pred_xgb, output_dict=True)\n",
    "\n",
    "# Extract precision, recall, f1-score for each class and overall\n",
    "precision_xgb = report_xgb['macro avg']['precision']\n",
    "recall_xgb = report_xgb['macro avg']['recall']\n",
    "f1_xgb = report_xgb['macro avg']['f1-score']\n",
    "\n",
    "# Print metrics for XGBoost\n",
    "print(f\"XGBoost Accuracy: {xgb_accuracy:.4f}\")\n",
    "print(f\"XGBoost Precision: {precision_xgb:.4f}\")\n",
    "print(f\"XGBoost Recall: {recall_xgb:.4f}\")\n",
    "print(f\"XGBoost F1 Score: {f1_xgb:.4f}\")\n",
    "print(f\"Training time for XGBoost: {training_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2cc072c-91a2-4847-b968-3dbbf03c0f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.5409950\ttotal: 164ms\tremaining: 8.02s\n",
      "1:\tlearn: 0.3765519\ttotal: 172ms\tremaining: 4.12s\n",
      "2:\tlearn: 0.2731545\ttotal: 180ms\tremaining: 2.82s\n",
      "3:\tlearn: 0.2093947\ttotal: 188ms\tremaining: 2.16s\n",
      "4:\tlearn: 0.1710221\ttotal: 199ms\tremaining: 1.79s\n",
      "5:\tlearn: 0.1379649\ttotal: 208ms\tremaining: 1.53s\n",
      "6:\tlearn: 0.1247375\ttotal: 219ms\tremaining: 1.35s\n",
      "7:\tlearn: 0.1089347\ttotal: 229ms\tremaining: 1.2s\n",
      "8:\tlearn: 0.0961965\ttotal: 237ms\tremaining: 1.08s\n",
      "9:\tlearn: 0.0863497\ttotal: 245ms\tremaining: 981ms\n",
      "10:\tlearn: 0.0809860\ttotal: 252ms\tremaining: 894ms\n",
      "11:\tlearn: 0.0772648\ttotal: 258ms\tremaining: 818ms\n",
      "12:\tlearn: 0.0734794\ttotal: 265ms\tremaining: 753ms\n",
      "13:\tlearn: 0.0709997\ttotal: 271ms\tremaining: 697ms\n",
      "14:\tlearn: 0.0685744\ttotal: 277ms\tremaining: 647ms\n",
      "15:\tlearn: 0.0660479\ttotal: 284ms\tremaining: 604ms\n",
      "16:\tlearn: 0.0634723\ttotal: 290ms\tremaining: 563ms\n",
      "17:\tlearn: 0.0614176\ttotal: 297ms\tremaining: 528ms\n",
      "18:\tlearn: 0.0574031\ttotal: 304ms\tremaining: 496ms\n",
      "19:\tlearn: 0.0564979\ttotal: 310ms\tremaining: 465ms\n",
      "20:\tlearn: 0.0557630\ttotal: 317ms\tremaining: 438ms\n",
      "21:\tlearn: 0.0512251\ttotal: 325ms\tremaining: 413ms\n",
      "22:\tlearn: 0.0493167\ttotal: 331ms\tremaining: 388ms\n",
      "23:\tlearn: 0.0476406\ttotal: 337ms\tremaining: 366ms\n",
      "24:\tlearn: 0.0463967\ttotal: 344ms\tremaining: 344ms\n",
      "25:\tlearn: 0.0432989\ttotal: 351ms\tremaining: 324ms\n",
      "26:\tlearn: 0.0427107\ttotal: 357ms\tremaining: 304ms\n",
      "27:\tlearn: 0.0417737\ttotal: 363ms\tremaining: 286ms\n",
      "28:\tlearn: 0.0411785\ttotal: 370ms\tremaining: 268ms\n",
      "29:\tlearn: 0.0408014\ttotal: 376ms\tremaining: 251ms\n",
      "30:\tlearn: 0.0392616\ttotal: 383ms\tremaining: 235ms\n",
      "31:\tlearn: 0.0386662\ttotal: 392ms\tremaining: 220ms\n",
      "32:\tlearn: 0.0381867\ttotal: 400ms\tremaining: 206ms\n",
      "33:\tlearn: 0.0371246\ttotal: 409ms\tremaining: 192ms\n",
      "34:\tlearn: 0.0364916\ttotal: 416ms\tremaining: 178ms\n",
      "35:\tlearn: 0.0355996\ttotal: 423ms\tremaining: 165ms\n",
      "36:\tlearn: 0.0353421\ttotal: 430ms\tremaining: 151ms\n",
      "37:\tlearn: 0.0347411\ttotal: 436ms\tremaining: 138ms\n",
      "38:\tlearn: 0.0343972\ttotal: 442ms\tremaining: 125ms\n",
      "39:\tlearn: 0.0327808\ttotal: 449ms\tremaining: 112ms\n",
      "40:\tlearn: 0.0320330\ttotal: 455ms\tremaining: 99.9ms\n",
      "41:\tlearn: 0.0306366\ttotal: 462ms\tremaining: 87.9ms\n",
      "42:\tlearn: 0.0300136\ttotal: 468ms\tremaining: 76.2ms\n",
      "43:\tlearn: 0.0290463\ttotal: 474ms\tremaining: 64.7ms\n",
      "44:\tlearn: 0.0284846\ttotal: 480ms\tremaining: 53.4ms\n",
      "45:\tlearn: 0.0282646\ttotal: 487ms\tremaining: 42.3ms\n",
      "46:\tlearn: 0.0273007\ttotal: 493ms\tremaining: 31.5ms\n",
      "47:\tlearn: 0.0267096\ttotal: 499ms\tremaining: 20.8ms\n",
      "48:\tlearn: 0.0263919\ttotal: 506ms\tremaining: 10.3ms\n",
      "49:\tlearn: 0.0259618\ttotal: 512ms\tremaining: 0us\n",
      "CatBoost Accuracy: 0.9813\n",
      "CatBoost Precision: 0.9810\n",
      "CatBoost Recall: 0.9813\n",
      "CatBoost F1 Score: 0.9811\n",
      "Training time for CatBoost: 0.6705 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\preprocessing\\_label.py:153: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import time\n",
    "\n",
    "# Initialize the CatBoost model\n",
    "catboost_model = CatBoostClassifier(iterations=50, random_state=42, cat_features=[])\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the CatBoost model\n",
    "catboost_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_catboost = catboost_model.predict(X_test)\n",
    "\n",
    "# Convert predictions back to original labels\n",
    "y_pred_catboost = label_encoder.inverse_transform(y_pred_catboost)\n",
    "\n",
    "# Calculate accuracy\n",
    "catboost_accuracy = accuracy_score(y_test, y_pred_catboost)\n",
    "\n",
    "# Generate classification report\n",
    "report_catboost = classification_report(y_test, y_pred_catboost, output_dict=True)\n",
    "\n",
    "# Extract precision, recall, f1-score for each class and overall\n",
    "precision_catboost = report_catboost['macro avg']['precision']\n",
    "recall_catboost = report_catboost['macro avg']['recall']\n",
    "f1_catboost = report_catboost['macro avg']['f1-score']\n",
    "\n",
    "# Print metrics for CatBoost\n",
    "print(f\"CatBoost Accuracy: {catboost_accuracy:.4f}\")\n",
    "print(f\"CatBoost Precision: {precision_catboost:.4f}\")\n",
    "print(f\"CatBoost Recall: {recall_catboost:.4f}\")\n",
    "print(f\"CatBoost F1 Score: {f1_catboost:.4f}\")\n",
    "print(f\"Training time for CatBoost: {training_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d066014f-365e-4aca-99a6-3293fcdf778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "# Define models\n",
    "def get_models():\n",
    "    return {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(),\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"SVM\": SVC(kernel='linear', probability=True),\n",
    "        \"AdaBoost\": AdaBoostClassifier(n_estimators=100),\n",
    "        \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "        \"LightGBM\": lgb.LGBMClassifier(),\n",
    "        \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "        \"CatBoost\": cb.CatBoostClassifier(verbose=0)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13110136-0a37-4768-91c4-fcf69475c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train and evaluate models\n",
    "def train_evaluate_models(X_train, X_test, y_train, y_test):\n",
    "    models = get_models()\n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"Training {name}...\")\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        precision = report['macro avg']['precision']\n",
    "        recall = report['macro avg']['recall']\n",
    "        f1 = report['macro avg']['f1-score']\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1 Score\": f1,\n",
    "            \"Training Time (s)\": training_time\n",
    "        }\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"{name} Precision: {precision:.4f}\")\n",
    "        print(f\"{name} Recall: {recall:.4f}\")\n",
    "        print(f\"{name} F1 Score: {f1:.4f}\")\n",
    "        print(f\"Training Time: {training_time:.4f} seconds\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage (assuming X_train, X_test, y_train, y_test are defined)\n",
    "# results = train_evaluate_models(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0da588f-8092-459e-a92b-118c336a7035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "# Define models\n",
    "def get_models():\n",
    "    return {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(),\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"SVM\": SVC(kernel='linear', probability=True),\n",
    "        \"AdaBoost\": AdaBoostClassifier(n_estimators=100),\n",
    "        \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "        \"LightGBM\": lgb.LGBMClassifier(),\n",
    "        \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "        \"CatBoost\": cb.CatBoostClassifier(verbose=0)\n",
    "    }\n",
    "\n",
    "# Train and evaluate models\n",
    "def train_evaluate_models(X_train, X_test, y_train, y_test):\n",
    "    models = get_models()\n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"Training {name}...\")\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        precision = report['macro avg']['precision']\n",
    "        recall = report['macro avg']['recall']\n",
    "        f1 = report['macro avg']['f1-score']\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1 Score\": f1,\n",
    "            \"Training Time (s)\": training_time\n",
    "        }\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"{name} Precision: {precision:.4f}\")\n",
    "        print(f\"{name} Recall: {recall:.4f}\")\n",
    "        print(f\"{name} F1 Score: {f1:.4f}\")\n",
    "        print(f\"Training Time: {training_time:.4f} seconds\\n\")\n",
    "    \n",
    "    # Print all results\n",
    "    print(\"\\nFinal Results for All Models:\")\n",
    "    for model, metrics in results.items():\n",
    "        print(f\"\\nModel: {model}\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage (assuming X_train, X_test, y_train, y_test are defined)\n",
    "# results = train_evaluate_models(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c7c55ed-57b2-40cb-848d-6abb965ecc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8923\n",
      "Logistic Regression Precision: 0.8948\n",
      "Logistic Regression Recall: 0.8908\n",
      "Logistic Regression F1 Score: 0.8907\n",
      "Training Time: 0.0221 seconds\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.9742\n",
      "Random Forest Precision: 0.9742\n",
      "Random Forest Recall: 0.9738\n",
      "Random Forest F1 Score: 0.9738\n",
      "Training Time: 0.5144 seconds\n",
      "\n",
      "Training Decision Tree...\n",
      "Decision Tree Accuracy: 0.9180\n",
      "Decision Tree Precision: 0.9170\n",
      "Decision Tree Recall: 0.9170\n",
      "Decision Tree F1 Score: 0.9170\n",
      "Training Time: 0.0382 seconds\n",
      "\n",
      "Training KNN...\n",
      "KNN Accuracy: 0.9438\n",
      "KNN Precision: 0.9439\n",
      "KNN Recall: 0.9435\n",
      "KNN F1 Score: 0.9431\n",
      "Training Time: 0.0010 seconds\n",
      "\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.8993\n",
      "SVM Precision: 0.9074\n",
      "SVM Recall: 0.8962\n",
      "SVM F1 Score: 0.8960\n",
      "Training Time: 0.1905 seconds\n",
      "\n",
      "Training AdaBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.6581\n",
      "AdaBoost Precision: 0.5333\n",
      "AdaBoost Recall: 0.6437\n",
      "AdaBoost F1 Score: 0.5459\n",
      "Training Time: 0.4967 seconds\n",
      "\n",
      "Training Gaussian Naive Bayes...\n",
      "Gaussian Naive Bayes Accuracy: 0.8314\n",
      "Gaussian Naive Bayes Precision: 0.8476\n",
      "Gaussian Naive Bayes Recall: 0.8320\n",
      "Gaussian Naive Bayes F1 Score: 0.8302\n",
      "Training Time: 0.0000 seconds\n",
      "\n",
      "Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4203\n",
      "[LightGBM] [Info] Number of data points in the train set: 1705, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score -1.104495\n",
      "[LightGBM] [Info] Start training from score -1.099199\n",
      "[LightGBM] [Info] Start training from score -1.092181\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM Accuracy: 0.9766\n",
      "LightGBM Precision: 0.9764\n",
      "LightGBM Recall: 0.9762\n",
      "LightGBM F1 Score: 0.9762\n",
      "Training Time: 0.2872 seconds\n",
      "\n",
      "Training XGBoost...\n",
      "XGBoost Accuracy: 0.9789\n",
      "XGBoost Precision: 0.9792\n",
      "XGBoost Recall: 0.9783\n",
      "XGBoost F1 Score: 0.9785\n",
      "Training Time: 0.2013 seconds\n",
      "\n",
      "Training CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py:158: UserWarning: [22:56:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Accuracy: 0.9859\n",
      "CatBoost Precision: 0.9859\n",
      "CatBoost Recall: 0.9857\n",
      "CatBoost F1 Score: 0.9857\n",
      "Training Time: 9.1728 seconds\n",
      "\n",
      "\n",
      "Final Results for All Models:\n",
      "\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.8923\n",
      "Precision: 0.8948\n",
      "Recall: 0.8908\n",
      "F1 Score: 0.8907\n",
      "Training Time (s): 0.0221\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.9742\n",
      "Precision: 0.9742\n",
      "Recall: 0.9738\n",
      "F1 Score: 0.9738\n",
      "Training Time (s): 0.5144\n",
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.9180\n",
      "Precision: 0.9170\n",
      "Recall: 0.9170\n",
      "F1 Score: 0.9170\n",
      "Training Time (s): 0.0382\n",
      "\n",
      "Model: KNN\n",
      "Accuracy: 0.9438\n",
      "Precision: 0.9439\n",
      "Recall: 0.9435\n",
      "F1 Score: 0.9431\n",
      "Training Time (s): 0.0010\n",
      "\n",
      "Model: SVM\n",
      "Accuracy: 0.8993\n",
      "Precision: 0.9074\n",
      "Recall: 0.8962\n",
      "F1 Score: 0.8960\n",
      "Training Time (s): 0.1905\n",
      "\n",
      "Model: AdaBoost\n",
      "Accuracy: 0.6581\n",
      "Precision: 0.5333\n",
      "Recall: 0.6437\n",
      "F1 Score: 0.5459\n",
      "Training Time (s): 0.4967\n",
      "\n",
      "Model: Gaussian Naive Bayes\n",
      "Accuracy: 0.8314\n",
      "Precision: 0.8476\n",
      "Recall: 0.8320\n",
      "F1 Score: 0.8302\n",
      "Training Time (s): 0.0000\n",
      "\n",
      "Model: LightGBM\n",
      "Accuracy: 0.9766\n",
      "Precision: 0.9764\n",
      "Recall: 0.9762\n",
      "F1 Score: 0.9762\n",
      "Training Time (s): 0.2872\n",
      "\n",
      "Model: XGBoost\n",
      "Accuracy: 0.9789\n",
      "Precision: 0.9792\n",
      "Recall: 0.9783\n",
      "F1 Score: 0.9785\n",
      "Training Time (s): 0.2013\n",
      "\n",
      "Model: CatBoost\n",
      "Accuracy: 0.9859\n",
      "Precision: 0.9859\n",
      "Recall: 0.9857\n",
      "F1 Score: 0.9857\n",
      "Training Time (s): 9.1728\n"
     ]
    }
   ],
   "source": [
    "results = train_evaluate_models(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c45f067-ee09-4b7c-942e-1457ba20fa15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
